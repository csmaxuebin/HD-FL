{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of FL task\n",
    "from MLModel import *\n",
    "from FLModel import *\n",
    "from utils import *\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # data sets\n",
    "    data = []\n",
    "    for i in range(1, 7):\n",
    "        # d = np.load(\"/home/jyfan/data/bank/non-iid/3clients/bank\" + str(i) + \".npy\")\n",
    "        d = np.load(\"/home/jyfan/data/bank/non-iid/bank\" + str(i) + \".npy\")\n",
    "        data.append((d[:, :16], d[:, 16:].flatten()))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_mnist(num_users):\n",
    "    # data_train = datasets.MNIST(root=\"~/data/\", train=True, transform=transforms.ToTensor())\n",
    "    data_train = datasets.MNIST(root=\"~/data/\", train=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "    # data_test = datasets.MNIST(root=\"~/data/\", train=False, transform=transforms.ToTensor())\n",
    "    data_test = datasets.MNIST(root=\"~/data/\", train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "    # split MNIST (training set) into non-iid data sets\n",
    "    non_iid = []\n",
    "    '''\n",
    "    for i in range(0, 10):\n",
    "        idx = np.where(data_train.targets == i)\n",
    "        d = data_train.data[idx].flatten(1).float()\n",
    "        targets = data_train.targets[idx].float()\n",
    "        non_iid.append((d, targets))\n",
    "    non_iid.append((data_test.data.flatten(1).float(), data_test.targets.float()))\n",
    "    '''\n",
    "    user_dict = mnist_noniid(data_train, num_users)\n",
    "    for i in range(num_users):\n",
    "        idx = user_dict[i]\n",
    "        d = data_train.data[idx].flatten(1).float()\n",
    "        targets = data_train.targets[idx].float()\n",
    "        non_iid.append((d, targets))\n",
    "    non_iid.append((data_test.data.flatten(1).float(), data_test.targets.float()))\n",
    "    return non_iid\n",
    "\n",
    "\n",
    "def load_p(latent):\n",
    "    pth = \"/home/jyfan/data/MNIST/\"\n",
    "    non_iid_p = []\n",
    "    for i in range(10):\n",
    "        d = np.load(pth + \"non-iid-p/\" + str(latent) + \"/P_\" + str(i) + \".npy\")\n",
    "        d = (d.T / abs(d).max(1)).T\n",
    "        target = [i*1.0 for ii in range(d.shape[0])]\n",
    "        non_iid_p.append((np.array(d), np.array(target)))\n",
    "    test = np.load(pth + \"non-iid-p/\" + str(latent) + \"/P10_test.npy\")\n",
    "    test = (test.T / abs(test).max(1)).T\n",
    "    t_label = np.load(pth + \"non-iid-p/\" + str(latent) + \"/test_label.npy\")\n",
    "    non_iid_p.append((test, t_label))\n",
    "    return non_iid_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. load_data\n",
    "2. generate clients (step 3)\n",
    "3. generate aggregator\n",
    "4. training\n",
    "\"\"\"\n",
    "# d = load_data()\n",
    "client_num = 10\n",
    "d = load_mnist(client_num)\n",
    "#d = load_p(latent=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_par = {\n",
    "    'output_size': 10,\n",
    "    'client_num': client_num,\n",
    "    'model': MLP,\n",
    "    'data': d,\n",
    "    'lr': 0.001,\n",
    "    'E': 5,\n",
    "    'C': 1,\n",
    "    'epsilon': 1.0,\n",
    "    'delta': 1e-4,\n",
    "    'clip': 200,\n",
    "    'tot_E': 10,\n",
    "    'batch_size': 32,\n",
    "    'device': device\n",
    "}\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fl_entity = FLServer(fl_par).to(device)\n",
    "#fl_entity.global_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->name: model.0.weight -->grad_requirs: True  -->grad_value: None\n",
      "-->name: model.0.bias -->grad_requirs: True  -->grad_value: None\n",
      "-->name: model.3.weight -->grad_requirs: True  -->grad_value: None\n",
      "-->name: model.3.bias -->grad_requirs: True  -->grad_value: None\n"
     ]
    }
   ],
   "source": [
    "for name, parms in fl_entity.clients[1].model.named_parameters(): #.grad.state_dict()\n",
    "    print('-->name:', name, '-->grad_requirs:',parms.requires_grad, ' -->grad_value:',parms.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fl_entity.global_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epochs = 1, acc = 0.2070\n",
      "global epochs = 2, acc = 0.3379\n",
      "global epochs = 3, acc = 0.4186\n",
      "global epochs = 4, acc = 0.4773\n",
      "global epochs = 5, acc = 0.5120\n",
      "global epochs = 6, acc = 0.5475\n",
      "global epochs = 7, acc = 0.5668\n",
      "global epochs = 8, acc = 0.5970\n",
      "global epochs = 9, acc = 0.6202\n",
      "global epochs = 10, acc = 0.6371\n"
     ]
    }
   ],
   "source": [
    "fl_entity.global_update_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 784])\n",
      "torch.Size([200])\n",
      "torch.Size([10, 200])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#print(fl_entity.clients[1].state_dict()['model.model.0.weight'].grad)\n",
    "#print(fl_entity.clients[0].state_dict()['model.model.0.bias'].grad)\n",
    "import copy\n",
    "d=dict(fl_entity.clients[0].model.named_parameters())\n",
    "grad = {}\n",
    "for name in d:\n",
    "    grad[name] = copy.deepcopy(d[name].grad)\n",
    "    print(grad[name].shape)\n",
    "\n",
    "d=dict(fl_entity.clients[1].model.named_parameters())\n",
    "grad2 = {}\n",
    "for name in d:\n",
    "    grad2[name] = copy.deepcopy(d[name].grad)\n",
    "#x=dict(fl_entity.clients[1].model.named_parameters())\n",
    "#x['model.0.weight']\n",
    "#for name, parms in fl_entity.clients[1].model.named_parameters(): #.grad.state_dict()\n",
    "    #print('-->name:', name, '-->grad_requirs:',parms.requires_grad, ' -->grad_value:',parms.grad)\n",
    "    #input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
